{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xpokidSmE3Xc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f=open('/content/bottxt.txt','r',errors='ignore')\n",
        "raw_doc=f.read()"
      ],
      "metadata": {
        "id": "5Akzg24QPCLq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_doc"
      ],
      "metadata": {
        "id": "DJIE2xV9PWfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from nltk.corpus.reader.tagged import word_tokenize\n",
        "# data preprocessing\n",
        "raw_doc= raw_doc.lower()\n",
        "nltk.download('punkt') #using the punkt tokenizer\n",
        "nltk.download('wordnet') # using the wordnet dictionary\n",
        "nltk.download('omw-1.4')\n",
        "sentence_tokens=nltk.sent_tokenize(raw_doc)\n",
        "word_tokens=nltk.word_tokenize(raw_doc)"
      ],
      "metadata": {
        "id": "hSJzqxrRPbbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_tokens[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAGABmLjUNVq",
        "outputId": "d5ca0b51-e046-489d-cc91-7c192338e516"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nchatbot\\nfrom wikipedia, the free encyclopedia\\njump to navigationjump to search\\nfor other uses, see chatbot (disambiguation).',\n",
              " 'a virtual assistant chatbot\\n\\nthe 1966 eliza chatbot\\na chatbot or chatterbot is a software application used to conduct an on-line chat conversation via text or text-to-speech, in lieu of providing direct contact with a live human agent.',\n",
              " '[1][2] designed to convincingly simulate the way a human would behave as a conversational partner, chatbot systems typically require continuous tuning and testing, and many in production remain unable to adequately converse, while none of them can pass the standard turing test.',\n",
              " '[3] the term \"chatterbot\" was originally coined by michael mauldin (creator of the first verbot) in 1994 to describe these conversational programs.']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokens[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8Fqu9P1URGo",
        "outputId": "e17c3931-d288-414e-a563-cdbd174a63fb"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['chatbot', 'from', 'wikipedia', ',', 'the']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# text-PreProcessing steps\n",
        "lemer=nltk.stem.WordNetLemmatizer()\n",
        "def Lemtokens(tokens):\n",
        "  return [lemer.lemmatize(token) for token in tokens] \n",
        "remove_punc_dict=dict((ord(punct),None) for punct in string.punctuation)  \n",
        "def LemNormalize(text):\n",
        "  return Lemtokens(nltk.word_tokenize(text.lower().translate(remove_punc_dict)))"
      ],
      "metadata": {
        "id": "xynFx0F0UVJC"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define greetings function\n",
        "greet_inputs=('hello','hi','whassup','how are you?')\n",
        "greet_responses=('hi','Hey','Hey There','There three!')\n",
        "def great(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in  greet_inputs:\n",
        "      return random.choice(greet_responses)"
      ],
      "metadata": {
        "id": "9-GV1602XKzA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Response Generation by the bot \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "xwYc7dehZPOg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
        "  tfidf=TfidfVec.fit_transform(sentence_tokens)\n",
        "  vals=cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx=vals.argsort()[0][-2] #argsort most similar in cosine similarity\n",
        "  flat=vals.flatten() #converting multi-dimensional array into one dimensional flatten array\n",
        "  flat.sort()\n",
        "  req_tfidf=flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response + \"I am sorry.Unable to understand you!\"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response=robo1_response + sentence_tokens[idx]\n",
        "    return robo1_response  \n",
        "  "
      ],
      "metadata": {
        "id": "xiG3E8UMZv8j"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the chatflow\n",
        "flag =True\n",
        "print('Hello! I am the Learning Bot.Start typing your text after greeting to talk to me.For ending  type bye!')\n",
        "while(flag == True):\n",
        "   user_response=input()\n",
        "   user_response=user_response.lower()\n",
        "   if(user_response !='bye'):\n",
        "     if(user_response == 'thank you' or user_response =='thanks'):\n",
        "       flag =False\n",
        "       print('Bot: You are welcome..')\n",
        "     else:\n",
        "       if(great(user_response)!=None):\n",
        "         print('Bot'+great(user_response))\n",
        "       else:\n",
        "         sentence_tokens.append(user_response)\n",
        "         word_tokens=word_tokens + nltk.word_tokenize(user_response)\n",
        "         final_words=list(set(word_tokens))\n",
        "         print('Bot: ',end='')\n",
        "         print(response(user_response)) # using cosine similarity\n",
        "         sentence_tokens.remove(user_response)\n",
        "   else:\n",
        "      flag = False\n",
        "      print('Bot:Goodbye!')    \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ydC9ygF-wyr",
        "outputId": "119972e7-d05f-40ee-fb6d-4da05737e482"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am the Learning Bot.Start typing your text after greeting to talk to me.For ending convo type bye!\n",
            "hi\n",
            "BotHey There\n",
            "tonoy\n",
            "Bot: I am sorry.Unable to understand you!\n",
            "can you tell me about turning test\n",
            "Bot: by responding to any input that contains the word 'mother' with 'tell me more about your family').\n",
            "ELIZA's key method of operation\n",
            "Bot: [7]\n",
            "\n",
            "eliza's key method of operation (copied by chatbot designers ever since) involves the recognition of clue words or phrases in the input, and the output of the corresponding pre-prepared or pre-programmed responses that can move the conversation forward in an apparently meaningful way (e.g.\n",
            "method\n",
            "Bot: this sort of usage holds the prospect of moving chatbot technology from weizenbaum's \"shelf ... reserved for curios\" to that marked \"genuinely useful computational methods\".\n",
            "thanks\n",
            "Bot: You are welcome..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kilt0BCdNGwd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}